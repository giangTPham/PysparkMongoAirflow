Spark Executor Command: "/home/gitpod/.sdkman/candidates/java/current/bin/java" "-cp" "/workspace/PysparkMongoAirflow/spark-3.1.1-bin-hadoop2.7/conf/:/workspace/PysparkMongoAirflow/spark-3.1.1-bin-hadoop2.7/jars/*" "-Xmx1024M" "-Dspark.driver.port=43379" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@10.0.2.100:43379" "--executor-id" "0" "--hostname" "10.0.2.100" "--cores" "1" "--app-id" "app-20220302075138-0010" "--worker-url" "spark://Worker@10.0.2.100:36917"
========================================

Picked up JAVA_TOOL_OPTIONS:  -Xmx3435m
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/03/02 07:51:39 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 35593@giangtpham-pysparkmongoa-8e4ves7r5or
22/03/02 07:51:39 INFO SignalUtils: Registering signal handler for TERM
22/03/02 07:51:39 INFO SignalUtils: Registering signal handler for HUP
22/03/02 07:51:39 INFO SignalUtils: Registering signal handler for INT
22/03/02 07:51:40 WARN Utils: Your hostname, giangtpham-pysparkmongoa-8e4ves7r5or resolves to a loopback address: 127.0.0.1; using 10.0.2.100 instead (on interface tap0)
22/03/02 07:51:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/workspace/PysparkMongoAirflow/spark-3.1.1-bin-hadoop2.7/jars/spark-unsafe_2.12-3.1.1.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
22/03/02 07:51:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
22/03/02 07:51:40 INFO SecurityManager: Changing view acls to: gitpod
22/03/02 07:51:40 INFO SecurityManager: Changing modify acls to: gitpod
22/03/02 07:51:40 INFO SecurityManager: Changing view acls groups to: 
22/03/02 07:51:40 INFO SecurityManager: Changing modify acls groups to: 
22/03/02 07:51:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(gitpod); groups with view permissions: Set(); users  with modify permissions: Set(gitpod); groups with modify permissions: Set()
22/03/02 07:51:41 INFO TransportClientFactory: Successfully created connection to /10.0.2.100:43379 after 74 ms (0 ms spent in bootstraps)
22/03/02 07:51:41 INFO SecurityManager: Changing view acls to: gitpod
22/03/02 07:51:41 INFO SecurityManager: Changing modify acls to: gitpod
22/03/02 07:51:41 INFO SecurityManager: Changing view acls groups to: 
22/03/02 07:51:41 INFO SecurityManager: Changing modify acls groups to: 
22/03/02 07:51:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(gitpod); groups with view permissions: Set(); users  with modify permissions: Set(gitpod); groups with modify permissions: Set()
22/03/02 07:51:41 INFO TransportClientFactory: Successfully created connection to /10.0.2.100:43379 after 2 ms (0 ms spent in bootstraps)
22/03/02 07:51:41 INFO DiskBlockManager: Created local directory at /tmp/spark-4b8a5c4f-fd59-4e7b-b712-4d7efa021ada/executor-8c96a5c0-94fb-4d06-bc9c-50a7e0e87376/blockmgr-f77cc2a0-608a-483d-a071-7aa85e6729fa
22/03/02 07:51:41 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
22/03/02 07:51:41 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@10.0.2.100:43379
22/03/02 07:51:41 INFO WorkerWatcher: Connecting to worker spark://Worker@10.0.2.100:36917
22/03/02 07:51:41 INFO TransportClientFactory: Successfully created connection to /10.0.2.100:36917 after 2 ms (0 ms spent in bootstraps)
22/03/02 07:51:41 INFO WorkerWatcher: Successfully connected to spark://Worker@10.0.2.100:36917
22/03/02 07:51:41 INFO ResourceUtils: ==============================================================
22/03/02 07:51:41 INFO ResourceUtils: No custom resources configured for spark.executor.
22/03/02 07:51:41 INFO ResourceUtils: ==============================================================
22/03/02 07:51:41 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
22/03/02 07:51:41 INFO Executor: Starting executor ID 0 on host 10.0.2.100
22/03/02 07:51:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37739.
22/03/02 07:51:41 INFO NettyBlockTransferService: Server created on 10.0.2.100:37739
22/03/02 07:51:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/03/02 07:51:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 10.0.2.100, 37739, None)
22/03/02 07:51:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 10.0.2.100, 37739, None)
22/03/02 07:51:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 10.0.2.100, 37739, None)
22/03/02 07:51:43 INFO CoarseGrainedExecutorBackend: Got assigned task 0
22/03/02 07:51:43 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
22/03/02 07:51:44 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
22/03/02 07:51:44 INFO TransportClientFactory: Successfully created connection to /10.0.2.100:46435 after 2 ms (0 ms spent in bootstraps)
22/03/02 07:51:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 434.4 MiB)
22/03/02 07:51:44 INFO TorrentBroadcast: Reading broadcast variable 1 took 130 ms
22/03/02 07:51:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.8 KiB, free 434.4 MiB)
22/03/02 07:51:44 INFO CodeGenerator: Code generated in 195.450127 ms
22/03/02 07:51:44 INFO FileScanRDD: Reading File path: file:///workspace/PysparkMongoAirflow/Final_Project/data/source/promotions/2021-11-05/part-00000-86a590bd-9635-4446-bdf3-319feb6bec9f-c000.csv, range: 0-50903, partition values: [empty row]
22/03/02 07:51:44 INFO CodeGenerator: Code generated in 12.152576 ms
22/03/02 07:51:44 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
22/03/02 07:51:44 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.1 KiB, free 434.4 MiB)
22/03/02 07:51:44 INFO TorrentBroadcast: Reading broadcast variable 0 took 14 ms
22/03/02 07:51:45 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 201.2 KiB, free 434.2 MiB)
22/03/02 07:51:45 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1607 bytes result sent to driver
22/03/02 07:51:45 INFO CoarseGrainedExecutorBackend: Got assigned task 1
22/03/02 07:51:45 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
22/03/02 07:51:45 INFO TorrentBroadcast: Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
22/03/02 07:51:45 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 434.2 MiB)
22/03/02 07:51:45 INFO TorrentBroadcast: Reading broadcast variable 3 took 11 ms
22/03/02 07:51:45 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.5 KiB, free 434.1 MiB)
22/03/02 07:51:46 INFO CodeGenerator: Code generated in 10.915176 ms
22/03/02 07:51:46 INFO FileScanRDD: Reading File path: file:///workspace/PysparkMongoAirflow/Final_Project/data/source/promotions/2021-11-05/part-00000-86a590bd-9635-4446-bdf3-319feb6bec9f-c000.csv, range: 0-50903, partition values: [empty row]
22/03/02 07:51:46 INFO TorrentBroadcast: Started reading broadcast variable 2 with 1 pieces (estimated total size 4.0 MiB)
22/03/02 07:51:46 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.1 KiB, free 434.1 MiB)
22/03/02 07:51:46 INFO TorrentBroadcast: Reading broadcast variable 2 took 13 ms
22/03/02 07:51:46 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 201.2 KiB, free 433.9 MiB)
22/03/02 07:51:46 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1657 bytes result sent to driver
22/03/02 07:51:47 INFO CoarseGrainedExecutorBackend: Got assigned task 2
22/03/02 07:51:47 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
22/03/02 07:51:47 INFO TorrentBroadcast: Started reading broadcast variable 5 with 1 pieces (estimated total size 4.0 MiB)
22/03/02 07:51:47 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 433.9 MiB)
22/03/02 07:51:47 INFO TorrentBroadcast: Reading broadcast variable 5 took 11 ms
22/03/02 07:51:47 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.8 KiB, free 433.9 MiB)
22/03/02 07:51:47 INFO FileScanRDD: Reading File path: file:///workspace/PysparkMongoAirflow/Final_Project/data/source/transactions/2021-11-05/part-00000-f068d0ea-6197-4788-b0e6-bf8245bdd452-c000.csv, range: 0-259128, partition values: [empty row]
22/03/02 07:51:47 INFO TorrentBroadcast: Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
22/03/02 07:51:47 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.1 KiB, free 433.9 MiB)
22/03/02 07:51:47 INFO TorrentBroadcast: Reading broadcast variable 4 took 11 ms
22/03/02 07:51:47 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 201.2 KiB, free 433.7 MiB)
22/03/02 07:51:47 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1577 bytes result sent to driver
22/03/02 07:51:47 INFO CoarseGrainedExecutorBackend: Got assigned task 3
22/03/02 07:51:47 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
22/03/02 07:51:47 INFO TorrentBroadcast: Started reading broadcast variable 7 with 1 pieces (estimated total size 4.0 MiB)
22/03/02 07:51:47 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 433.7 MiB)
22/03/02 07:51:47 INFO TorrentBroadcast: Reading broadcast variable 7 took 10 ms
22/03/02 07:51:47 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 15.6 KiB, free 433.7 MiB)
22/03/02 07:51:47 INFO FileScanRDD: Reading File path: file:///workspace/PysparkMongoAirflow/Final_Project/data/source/transactions/2021-11-05/part-00000-f068d0ea-6197-4788-b0e6-bf8245bdd452-c000.csv, range: 0-259128, partition values: [empty row]
22/03/02 07:51:47 INFO TorrentBroadcast: Started reading broadcast variable 6 with 1 pieces (estimated total size 4.0 MiB)
22/03/02 07:51:47 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 24.1 KiB, free 433.6 MiB)
22/03/02 07:51:47 INFO TorrentBroadcast: Reading broadcast variable 6 took 11 ms
22/03/02 07:51:47 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 201.2 KiB, free 433.4 MiB)
22/03/02 07:51:47 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1629 bytes result sent to driver
22/03/02 07:51:47 INFO CoarseGrainedExecutorBackend: Got assigned task 4
22/03/02 07:51:47 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
22/03/02 07:51:47 INFO TorrentBroadcast: Started reading broadcast variable 9 with 1 pieces (estimated total size 4.0 MiB)
22/03/02 07:51:47 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 433.5 MiB)
22/03/02 07:51:47 INFO TorrentBroadcast: Reading broadcast variable 9 took 36 ms
22/03/02 07:51:47 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 10.8 KiB, free 433.5 MiB)
22/03/02 07:51:47 INFO FileScanRDD: Reading File path: file:///workspace/PysparkMongoAirflow/Final_Project/data/source/users/2021-11-05/part-00000-75606f25-6127-44e6-bbfc-26de0e46b31d-c000.csv, range: 0-20360, partition values: [empty row]
22/03/02 07:51:47 INFO TorrentBroadcast: Started reading broadcast variable 8 with 1 pieces (estimated total size 4.0 MiB)
22/03/02 07:51:47 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 24.1 KiB, free 433.9 MiB)
22/03/02 07:51:47 INFO TorrentBroadcast: Reading broadcast variable 8 took 11 ms
22/03/02 07:51:47 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 201.2 KiB, free 433.9 MiB)
22/03/02 07:51:47 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1563 bytes result sent to driver
22/03/02 07:51:47 INFO CoarseGrainedExecutorBackend: Got assigned task 5
22/03/02 07:51:47 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
22/03/02 07:51:47 INFO TorrentBroadcast: Started reading broadcast variable 11 with 1 pieces (estimated total size 4.0 MiB)
22/03/02 07:51:47 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 434.2 MiB)
22/03/02 07:51:47 INFO TorrentBroadcast: Reading broadcast variable 11 took 10 ms
22/03/02 07:51:47 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 15.5 KiB, free 434.1 MiB)
22/03/02 07:51:47 INFO FileScanRDD: Reading File path: file:///workspace/PysparkMongoAirflow/Final_Project/data/source/users/2021-11-05/part-00000-75606f25-6127-44e6-bbfc-26de0e46b31d-c000.csv, range: 0-20360, partition values: [empty row]
22/03/02 07:51:47 INFO TorrentBroadcast: Started reading broadcast variable 10 with 1 pieces (estimated total size 4.0 MiB)
22/03/02 07:51:47 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 24.1 KiB, free 434.1 MiB)
22/03/02 07:51:47 INFO TorrentBroadcast: Reading broadcast variable 10 took 28 ms
22/03/02 07:51:47 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 201.2 KiB, free 433.9 MiB)
22/03/02 07:51:47 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1571 bytes result sent to driver
22/03/02 07:51:48 INFO CoarseGrainedExecutorBackend: Got assigned task 6
22/03/02 07:51:48 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
22/03/02 07:51:48 INFO TorrentBroadcast: Started reading broadcast variable 13 with 1 pieces (estimated total size 4.0 MiB)
22/03/02 07:51:48 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 56.2 KiB, free 433.9 MiB)
22/03/02 07:51:48 INFO TorrentBroadcast: Reading broadcast variable 13 took 9 ms
22/03/02 07:51:48 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 155.9 KiB, free 433.7 MiB)
22/03/02 07:51:48 INFO FileScanRDD: Reading File path: file:///workspace/PysparkMongoAirflow/Final_Project/data/source/promotions/2021-11-05/part-00000-86a590bd-9635-4446-bdf3-319feb6bec9f-c000.csv, range: 0-50903, partition values: [empty row]
22/03/02 07:51:48 INFO CodeGenerator: Code generated in 18.37384 ms
22/03/02 07:51:48 INFO TorrentBroadcast: Started reading broadcast variable 12 with 1 pieces (estimated total size 4.0 MiB)
22/03/02 07:51:48 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 433.7 MiB)
22/03/02 07:51:48 INFO TorrentBroadcast: Reading broadcast variable 12 took 10 ms
22/03/02 07:51:48 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 201.2 KiB, free 433.5 MiB)
22/03/02 07:51:48 INFO MemoryStore: Block rdd_33_0 stored as values in memory (estimated size 45.4 KiB, free 433.4 MiB)
22/03/02 07:51:48 INFO CodeGenerator: Code generated in 6.438207 ms
22/03/02 07:51:48 INFO CodeGenerator: Code generated in 38.793006 ms
22/03/02 07:51:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/03/02 07:51:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/03/02 07:51:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/03/02 07:51:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/03/02 07:51:48 INFO CodecConfig: Compression: SNAPPY
22/03/02 07:51:48 INFO CodecConfig: Compression: SNAPPY
22/03/02 07:51:48 INFO ParquetOutputFormat: Parquet block size to 134217728
22/03/02 07:51:48 INFO ParquetOutputFormat: Parquet page size to 1048576
22/03/02 07:51:48 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/03/02 07:51:48 INFO ParquetOutputFormat: Dictionary is on
22/03/02 07:51:48 INFO ParquetOutputFormat: Validation is off
22/03/02 07:51:48 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/03/02 07:51:48 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/03/02 07:51:48 INFO ParquetOutputFormat: Page size checking is: estimated
22/03/02 07:51:48 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/03/02 07:51:48 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/03/02 07:51:48 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "userid",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "voucherCode",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "status",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "campaignID",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "time",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 userid;
  optional binary voucherCode (UTF8);
  optional binary status (UTF8);
  optional int32 campaignID;
  optional binary time (UTF8);
}

       
22/03/02 07:51:48 INFO CodecPool: Got brand-new compressor [.snappy]
22/03/02 07:51:48 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 64267
22/03/02 07:51:48 INFO FileOutputCommitter: Saved output of task 'attempt_202203020751472828421289293627631_0006_m_000000_6' to file:/workspace/PysparkMongoAirflow/Final_Project/data/datalake/2021-11-05/promotion/_temporary/0/task_202203020751472828421289293627631_0006_m_000000
22/03/02 07:51:48 INFO SparkHadoopMapRedUtil: attempt_202203020751472828421289293627631_0006_m_000000_6: Committed
22/03/02 07:51:48 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 2601 bytes result sent to driver
22/03/02 07:51:49 INFO CoarseGrainedExecutorBackend: Got assigned task 7
22/03/02 07:51:49 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
22/03/02 07:51:49 INFO TorrentBroadcast: Started reading broadcast variable 15 with 1 pieces (estimated total size 4.0 MiB)
22/03/02 07:51:49 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 56.5 KiB, free 433.4 MiB)
22/03/02 07:51:49 INFO TorrentBroadcast: Reading broadcast variable 15 took 10 ms
22/03/02 07:51:49 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 156.7 KiB, free 433.2 MiB)
22/03/02 07:51:49 INFO FileScanRDD: Reading File path: file:///workspace/PysparkMongoAirflow/Final_Project/data/source/transactions/2021-11-05/part-00000-f068d0ea-6197-4788-b0e6-bf8245bdd452-c000.csv, range: 0-259128, partition values: [empty row]
22/03/02 07:51:49 INFO CodeGenerator: Code generated in 20.720704 ms
22/03/02 07:51:49 INFO TorrentBroadcast: Started reading broadcast variable 14 with 1 pieces (estimated total size 4.0 MiB)
22/03/02 07:51:49 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 433.2 MiB)
22/03/02 07:51:49 INFO TorrentBroadcast: Reading broadcast variable 14 took 11 ms
22/03/02 07:51:49 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 201.2 KiB, free 433.0 MiB)
22/03/02 07:51:49 INFO MemoryStore: Block rdd_42_0 stored as values in memory (estimated size 240.3 KiB, free 432.8 MiB)
22/03/02 07:51:49 INFO CodeGenerator: Code generated in 28.779773 ms
22/03/02 07:51:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/03/02 07:51:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/03/02 07:51:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/03/02 07:51:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/03/02 07:51:49 INFO CodecConfig: Compression: SNAPPY
22/03/02 07:51:49 INFO CodecConfig: Compression: SNAPPY
22/03/02 07:51:49 INFO ParquetOutputFormat: Parquet block size to 134217728
22/03/02 07:51:49 INFO ParquetOutputFormat: Parquet page size to 1048576
22/03/02 07:51:49 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/03/02 07:51:49 INFO ParquetOutputFormat: Dictionary is on
22/03/02 07:51:49 INFO ParquetOutputFormat: Validation is off
22/03/02 07:51:49 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/03/02 07:51:49 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/03/02 07:51:49 INFO ParquetOutputFormat: Page size checking is: estimated
22/03/02 07:51:49 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/03/02 07:51:49 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/03/02 07:51:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "transId",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "transStatus",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "userId",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "transactionTime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "appId",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "transType",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "amount",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "pmcId",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary transId (UTF8);
  optional int32 transStatus;
  optional int32 userId;
  optional binary transactionTime (UTF8);
  optional int32 appId;
  optional int32 transType;
  optional int32 amount;
  optional int32 pmcId;
}

       
22/03/02 07:51:49 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 340785
22/03/02 07:51:49 INFO FileOutputCommitter: Saved output of task 'attempt_202203020751493160379449513277177_0007_m_000000_7' to file:/workspace/PysparkMongoAirflow/Final_Project/data/datalake/2021-11-05/transaction/_temporary/0/task_202203020751493160379449513277177_0007_m_000000
22/03/02 07:51:49 INFO SparkHadoopMapRedUtil: attempt_202203020751493160379449513277177_0007_m_000000_7: Committed
22/03/02 07:51:49 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2515 bytes result sent to driver
22/03/02 07:51:49 INFO CoarseGrainedExecutorBackend: Got assigned task 8
22/03/02 07:51:49 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
22/03/02 07:51:49 INFO TorrentBroadcast: Started reading broadcast variable 17 with 1 pieces (estimated total size 4.0 MiB)
22/03/02 07:51:49 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 56.1 KiB, free 432.7 MiB)
22/03/02 07:51:49 INFO TorrentBroadcast: Reading broadcast variable 17 took 8 ms
22/03/02 07:51:49 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 155.9 KiB, free 432.6 MiB)
22/03/02 07:51:49 INFO FileScanRDD: Reading File path: file:///workspace/PysparkMongoAirflow/Final_Project/data/source/users/2021-11-05/part-00000-75606f25-6127-44e6-bbfc-26de0e46b31d-c000.csv, range: 0-20360, partition values: [empty row]
22/03/02 07:51:49 INFO CodeGenerator: Code generated in 9.518146 ms
22/03/02 07:51:49 INFO TorrentBroadcast: Started reading broadcast variable 16 with 1 pieces (estimated total size 4.0 MiB)
22/03/02 07:51:49 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 432.6 MiB)
22/03/02 07:51:49 INFO TorrentBroadcast: Reading broadcast variable 16 took 9 ms
22/03/02 07:51:49 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 201.2 KiB, free 432.4 MiB)
22/03/02 07:51:49 INFO MemoryStore: Block rdd_51_0 stored as values in memory (estimated size 21.8 KiB, free 432.3 MiB)
22/03/02 07:51:49 INFO CodeGenerator: Code generated in 14.328082 ms
22/03/02 07:51:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/03/02 07:51:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/03/02 07:51:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
22/03/02 07:51:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
22/03/02 07:51:49 INFO CodecConfig: Compression: SNAPPY
22/03/02 07:51:49 INFO CodecConfig: Compression: SNAPPY
22/03/02 07:51:49 INFO ParquetOutputFormat: Parquet block size to 134217728
22/03/02 07:51:49 INFO ParquetOutputFormat: Parquet page size to 1048576
22/03/02 07:51:49 INFO ParquetOutputFormat: Parquet dictionary page size to 1048576
22/03/02 07:51:49 INFO ParquetOutputFormat: Dictionary is on
22/03/02 07:51:49 INFO ParquetOutputFormat: Validation is off
22/03/02 07:51:49 INFO ParquetOutputFormat: Writer version is: PARQUET_1_0
22/03/02 07:51:49 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes
22/03/02 07:51:49 INFO ParquetOutputFormat: Page size checking is: estimated
22/03/02 07:51:49 INFO ParquetOutputFormat: Min row count for page size check is: 100
22/03/02 07:51:49 INFO ParquetOutputFormat: Max row count for page size check is: 10000
22/03/02 07:51:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "userid",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "birthdate",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "profileLevel",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "gender",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "updatedTime",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 userid;
  optional binary birthdate (UTF8);
  optional int32 profileLevel;
  optional int32 gender;
  optional binary updatedTime (UTF8);
}

       
22/03/02 07:51:49 INFO InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 29484
22/03/02 07:51:49 INFO FileOutputCommitter: Saved output of task 'attempt_202203020751496477970568185221618_0008_m_000000_8' to file:/workspace/PysparkMongoAirflow/Final_Project/data/datalake/2021-11-05/user/_temporary/0/task_202203020751496477970568185221618_0008_m_000000
22/03/02 07:51:49 INFO SparkHadoopMapRedUtil: attempt_202203020751496477970568185221618_0008_m_000000_8: Committed
22/03/02 07:51:49 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2515 bytes result sent to driver
22/03/02 07:51:49 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
22/03/02 07:51:49 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
tdown
